"""
TravelAgent: LLM-driven agent with function calling.
Replaces SemanticRouter + QueryStore pipeline.
"""
import json
import logging
import os
from typing import Any, Dict, List, Optional

from langchain_community.chat_models import ChatOllama

from tools.definitions import TRAVEL_TOOLS
from tools.executor import ToolExecutor

logger = logging.getLogger(__name__)

SYSTEM_PROMPT = """Báº¡n lÃ  T-Bot, má»™t hÆ°á»›ng dáº«n viÃªn du lá»‹ch AI thÃ´ng minh vÃ  thÃ¢n thiá»‡n.

NHIá»†M Vá»¤:
- Tráº£ lá»i cÃ¢u há»i vá» cÃ¡c Ä‘á»‹a Ä‘iá»ƒm du lá»‹ch
- Sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ (tools) Ä‘á»ƒ tÃ¬m thÃ´ng tin chÃ­nh xÃ¡c
- Náº¿u khÃ´ng tÃ¬m tháº¥y, thÃ nh tháº­t nÃ³i khÃ´ng biáº¿t

NGUYÃŠN Táº®C:
1. LUÃ”N Æ°u tiÃªn dÃ¹ng tool Ä‘á»ƒ tÃ¬m thÃ´ng tin, KHÃ”NG Ä‘Æ°á»£c bá»‹a
2. Tráº£ lá»i ngáº¯n gá»n, thÃ¢n thiá»‡n vá»›i "dáº¡/áº¡/nhÃ©"
3. Náº¿u user chÃ o há»i (xin chÃ o, cáº£m Æ¡n...), tráº£ lá»i trá»±c tiáº¿p khÃ´ng cáº§n tool
4. Náº¿u tool tráº£ vá» found=False, thÃ´ng bÃ¡o khÃ´ng tÃ¬m tháº¥y

CÃC TOOL CÃ“ Sáº´N:
- get_place_info: Láº¥y thÃ´ng tin giá»›i thiá»‡u Ä‘á»‹a Ä‘iá»ƒm
- get_place_location: Láº¥y vá»‹ trÃ­, Ä‘á»‹a chá»‰
- get_place_media: Láº¥y video, audio
- get_attractions: Láº¥y danh sÃ¡ch Ä‘iá»ƒm tham quan
- search_places: TÃ¬m kiáº¿m Ä‘á»‹a Ä‘iá»ƒm (dÃ¹ng khi khÃ´ng biáº¿t tÃªn chÃ­nh xÃ¡c)

Äá»ŠNH Dáº NG RESPONSE:
- DÃ¹ng emoji phÃ¹ há»£p (ğŸ“ cho vá»‹ trÃ­, ğŸ¬ cho video, ğŸ¯ cho Ä‘iá»ƒm tham quan)
- Káº¿t thÃºc báº±ng cÃ¢u há»i gá»£i Ã½ náº¿u phÃ¹ há»£p
"""


class TravelAgent:
    """LLM Agent vá»›i function calling cho travel chatbot."""

    def __init__(
        self,
        executor: ToolExecutor,
        model_name: str = None,
        max_iterations: int = 3
    ):
        """
        Args:
            executor: ToolExecutor instance for tool execution
            model_name: Ollama model name (default from env)
            max_iterations: Max tool call iterations
        """
        self.executor = executor
        self.max_iterations = max_iterations
        self.tools = TRAVEL_TOOLS
        
        # Get model from env or default
        model = model_name or os.getenv("OLLAMA_MODEL", "qwen2.5:7b")
        
        self.llm = ChatOllama(
            model=model,
            temperature=0.2,
            base_url=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
        )
        
        logger.info(f"TravelAgent initialized with model: {model}")

    async def run(
        self,
        query: str,
        context: Dict[str, Any],
        chat_history: Optional[List[Dict]] = None
    ) -> str:
        """
        Main agent loop.
        
        Args:
            query: User question
            context: {region_id, project_id, user_location}
            chat_history: Previous messages for context
            
        Returns:
            Final response string
        """
        # Check for chitchat first (no tool needed)
        if self._is_chitchat(query):
            return await self._handle_chitchat(query)
        
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT}
        ]
        
        # Add chat history (last 3 turns = 6 messages)
        if chat_history:
            messages.extend(chat_history[-6:])
        
        messages.append({"role": "user", "content": query})
        
        for iteration in range(self.max_iterations):
            logger.debug(f"Agent iteration {iteration + 1}/{self.max_iterations}")
            
            try:
                # Call LLM with tools
                response = self.llm.invoke(
                    messages,
                    tools=self.tools,
                    tool_choice="auto"
                )
                
                # Check for tool calls
                if hasattr(response, 'tool_calls') and response.tool_calls:
                    for tool_call in response.tool_calls:
                        tool_name = tool_call.get("name")
                        tool_args = tool_call.get("args", {})
                        
                        logger.info(f"ğŸ”§ Tool call: {tool_name}({tool_args})")
                        
                        # Execute tool
                        result = await self.executor.execute(
                            tool_name, tool_args, context
                        )
                        
                        # Add tool result to messages
                        messages.append({
                            "role": "assistant",
                            "content": None,
                            "tool_calls": [tool_call]
                        })
                        messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call.get("id", tool_name),
                            "content": json.dumps(result, ensure_ascii=False)
                        })
                else:
                    # No tool calls = final answer
                    final_response = response.content.strip()
                    logger.info(f"âœ… Final response: {final_response[:100]}...")
                    return final_response
                    
            except Exception as e:
                logger.error(f"Agent error in iteration {iteration + 1}: {e}")
                if iteration == self.max_iterations - 1:
                    return f"Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i xáº£y ra khi xá»­ lÃ½ yÃªu cáº§u cá»§a báº¡n. Vui lÃ²ng thá»­ láº¡i."
        
        # Max iterations reached, try to synthesize from what we have
        return "Xin lá»—i, tÃ´i khÃ´ng thá»ƒ tÃ¬m Ä‘Æ°á»£c thÃ´ng tin phÃ¹ há»£p. Báº¡n cÃ³ thá»ƒ thá»­ há»i cá»¥ thá»ƒ hÆ¡n khÃ´ng áº¡?"

    def _is_chitchat(self, query: str) -> bool:
        """Quick check for chitchat queries that don't need tools."""
        chitchat_keywords = [
            "xin chÃ o", "chÃ o báº¡n", "hello", "hi ", "hey",
            "cáº£m Æ¡n", "thanks", "thank you", "cÃ¡m Æ¡n",
            "táº¡m biá»‡t", "bye", "goodbye",
            "báº¡n khá»e khÃ´ng", "báº¡n lÃ  ai", "tÃªn báº¡n lÃ  gÃ¬",
        ]
        query_lower = query.lower().strip()
        return any(kw in query_lower for kw in chitchat_keywords)

    async def _handle_chitchat(self, query: str) -> str:
        """Handle chitchat without using tools."""
        query_lower = query.lower()
        
        if any(kw in query_lower for kw in ["xin chÃ o", "chÃ o", "hello", "hi"]):
            return "Xin chÃ o báº¡n! ğŸ‘‹ MÃ¬nh lÃ  T-Bot, hÆ°á»›ng dáº«n viÃªn du lá»‹ch AI. Báº¡n muá»‘n tÃ¬m hiá»ƒu vá» Ä‘á»‹a Ä‘iá»ƒm nÃ o khÃ´ng áº¡?"
        
        if any(kw in query_lower for kw in ["cáº£m Æ¡n", "thanks", "cÃ¡m Æ¡n"]):
            return "Dáº¡ khÃ´ng cÃ³ chi áº¡! ğŸ˜Š Báº¡n cáº§n há»— trá»£ gÃ¬ thÃªm khÃ´ng nhÃ©?"
        
        if any(kw in query_lower for kw in ["táº¡m biá»‡t", "bye"]):
            return "Táº¡m biá»‡t báº¡n! ChÃºc báº¡n cÃ³ chuyáº¿n Ä‘i vui váº» nhÃ©! ğŸŒŸ"
        
        if "báº¡n lÃ  ai" in query_lower or "tÃªn báº¡n" in query_lower:
            return "MÃ¬nh lÃ  T-Bot, trá»£ lÃ½ du lá»‹ch AI cá»§a báº¡n. MÃ¬nh cÃ³ thá»ƒ giÃºp báº¡n tÃ¬m thÃ´ng tin vá» cÃ¡c Ä‘á»‹a Ä‘iá»ƒm du lá»‹ch, video, hÆ°á»›ng dáº«n Ä‘Æ°á»ng Ä‘i vÃ  nhiá»u thá»© khÃ¡c ná»¯a! ğŸ—ºï¸"
        
        # Default chitchat response
        return "MÃ¬nh lÃ  T-Bot, sáºµn sÃ ng há»— trá»£ báº¡n vá» cÃ¡c Ä‘á»‹a Ä‘iá»ƒm du lá»‹ch. Báº¡n muá»‘n tÃ¬m hiá»ƒu gÃ¬ áº¡?"
